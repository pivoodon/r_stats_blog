---
title: "Hypothesis testing: z-test vs t-test"
output:
  html_document: default
  word_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library("moments")
library("ggplot2")
library("latex2exp")
# library("tikzDevice")

```

A **one-sample z-test or t-test** examines the **null hypothesis** $H_0$ that an observed sample mean has been drawn from a population centered at some previously specified mean $\mu_0$. Due to the strength of the Law of Large Numbers (LLN) and the Central Limit theorem (CLT), the population is assumed to be normally distributed.

If the sample is drawn from the population, $\bar{X_n}$ is expected to be equal to $\mu$ under $H_0$. If the sample is not drawn from the population, $\bar{X_n}$ is expected to be different than $\mu_0$ under the **alternalte hypothesis** $H_A$. The problem in **hypothesis testing** is to find an appropriate **test statistic** $T_{stat}$ and an appropriate **critical value** $c$. If $T_{stat} > c$, $H_0$ is rejected; if $T_{stat}\leq c$, $H_0$ isn't rejected. 

Rejecting or accepting $H_0$ can lead to two types of errors: Rejecting $H_0$ when $H_0$ is true is called a **type I error**. Failing to reject $H_0$ when $H_0$ is false is called a **type II error**.


# z-test for a population mean (variance known)

Let $X_1, X_2, X_3, ...$ be a population of independent and identically distributed (iid) observations of size $N$ with mean $\mu_0$ **and known variance $\sigma^2$**. A sample of size $n$ is drawn at random from the population. The sample mean and variance of the random sample are given by $\bar{X_n}$ and $s^2$ respectively. By the CLT and LLN,

\begin{eqnarray}
\frac{\sqrt{n}(\bar{X_n}-\mu_0)}{\sigma}&\longrightarrow&\mathcal{N}\left(0,1\right). 
\end{eqnarray}

$\mathcal{N}\left(0,1\right)$ is commonly referred as a **Z-distribution**. Hence the test statistic is given by 

\begin{eqnarray}
Z_{stat}&=&\frac{\bar{X}-\mu_0}{\sigma/\sqrt{n}}. 
\end{eqnarray}

Notice the population variance is used to calculate the test statistic. 

The appropriate critical value $c$ is defined by the tails of the Z-distribution (Fig 1). For a **significance level** $\alpha$, $H_0: \mu=\mu_0$ is rejected if $Z_{stat}>z_{1-\alpha/2}$ or $Z_{stat}<z_{\alpha/2}$, where $z_{1-\alpha/2}$ and $z_{\alpha/2}$ are the upper and lower quantiles of order $1-\alpha/2$ and $\alpha/2$ of the Z-distribution. This is equivalent to saying $H_0: \mu=\mu_0$ is rejected if $|Z_{stat}|>z_{1-\alpha/2}$. If indeed $|Z_{stat}|>z_{1-\alpha/2}$, then the $H_A: \mu\neq\mu_0$ is favored.

The lower the $\alpha$ level, the harder it is to reject $H_0$ as $z_{1-\alpha}$ is further on the right tail and $z_{\alpha/2}$ is further on the left tail of the Z-distribution (Fig 1). Equivalently, the greater the magnitude of $Z_{stat}$, that is, $Z_{stat}>>z_{1-\alpha/2}$ or $Z_{stat}<<z_{\alpha/2}$, the greater the evidence against the $H_0$ that there is no significant difference. 

The probability of getting a value $Z_{stat}$ is called the **p-value**. The test is significant at the $\alpha$ level if and only if $p_{value}\leq\alpha$. $Z_{stat}$ and $p_{value}$ are inexorably linked. The greater the magnitude of $Z_{stat}$, the lower the probability of a such large number being computed by chance, i.e, the lower the $p_{value}$.

As mentioned, it is possible to compute a small $p_{value}$ and reject $H_0$ when $H_0$ is true. The probability of committing this type I error is given by:

\begin{eqnarray}
\mathbb{P}(reject \ H_0| H_0 \ true)&=&\mathbb{P}(|Z_{stat}|>z_{1-\alpha/2}|\mu=\mu_0)\\
&=&\mathbb{P}(Z_{stat}>z_{1-\alpha/2}|\mu=\mu_0) + \mathbb{P}(Z_{stat}<z_{\alpha/2}|\mu=\mu_0) \\
&=&\frac{\alpha}{2} + \frac{\alpha}{2} \\
&=&\alpha.
\end{eqnarray}



```{r z_dist, echo=TRUE, fig.width=8, fig.height=6, fig.align='center', fig.cap='Figure 1: Population parameters of Z-distribution in blue curve and yellow histogram are given by $\\mu_0 = 0, \\sigma = 1$. $H_0$ is rejected if $Z_{stat}>z_{1-\\alpha/2}$ or $Z_{stat}<z_{\\alpha/2}$ for each $\\alpha$ level. (a) $\\alpha = 0.10$: $5th (z_{0.10/2}=z_{0.05}=-1.645)$ and $95th (z_{1-0.10/2}=z_{0.95}=+1.645)$ are the lower and upper quantiles. (b) $\\alpha = 0.05$: $2.5th (z_{0.05/2}=z_{0.025}=-1.96)$ and $97.5th (z_{1-0.05/2}=z_{0.975}=+1.96)$ are the lower and upper quantiles. (c) $\\alpha = 0.01$: $0.5th (z_{0.01/2}=z_{0.005}=-2.575)$ and $99.5th (z_{1-0.01/2}=z_{0.995}=-2.575)$ are the lower and upper quantiles.'}

set.seed(1)
N <- 1000000
mu <- 0
sigma <- 1
population_z <- rnorm(N,mean = mu,sd = sigma)

par(mfrow=c(2,2))
hist(population_z,
 col="yellow",
 border="black",
 prob = TRUE,
 xlab = "",
 ylim = c(0.,0.4),
main = TeX('$\\alpha$=0.10'))
curve( dnorm(x, mean=0,sd=1), add=T,col="blue", lwd = 3)
abline(v=c(-1.645,1.645), col="red", lwd = 2, lty=2)
text(-3.2, 0.4, TeX('z_{0.05}=-1.645'), col="red")
text(3.2, 0.4, TeX('z_{0.95}=+1.645'), col="red")
mtext("(a)", side=1, line = 4)

hist(population_z,
 col="yellow",
 border="black",
 prob = TRUE,
 xlab = "",
 ylim = c(0.,0.4),
main = TeX('$\\alpha$=0.05'))
curve( dnorm(x, mean=0,sd=1), add=T,col="blue", lwd = 3)
abline(v=c(-1.96,1.96), col="darkgreen", lwd = 2, lty=2)
text(-3.4, 0.4, TeX('z_{0.025}=-1.96'), col="darkgreen")
text(3.4, 0.4, TeX('z_{0.975}=+1.96'), col="darkgreen")
mtext("(b)", side=1, line = 4)

hist(population_z,
 col="yellow",
 border="black",
 prob = TRUE,
 xlab = "",
 ylim = c(0.,0.4),
main = TeX('$\\alpha$=0.01'))
curve( dnorm(x, mean=0,sd=1), add=T,col="blue", lwd = 3)
abline(v=c(-2.575,2.575), col="black", lwd = 2, lty=2)
text(-3.6, 0.4, TeX('z_{0.005}=-2.575'))
text(3.6, 0.4, TeX('z_{0.995}=+2.575'))
mtext("(c)", side=1, line = 4)

```



# t-test for a population mean (variance unknown)

Let $X_1, X_2, X_3, ...$ be a population of independent and identically distributed (iid) observations of size $N$ with **mean $\mu_0$ and unknown variance**. Similarly, a sample of size $n$ is drawn at random from the population. The sample mean and variance of the random sample are given by $\bar{X_n}$ and $s^2$ respectively. By the CLT and LLN,

\begin{eqnarray}
\frac{\sqrt{n}(\bar{X_n}-\mu_0)}{s}&\longrightarrow&\mathcal{t}_{n-1}, 
\end{eqnarray}

$t_{n-1}$ is referred as a **t-distribution**. Now,the test statistic is given by 

\begin{eqnarray}
T_{stat}&=&\frac{\bar{X}-\mu_0}{s/\sqrt{n}}. 
\end{eqnarray}

Unlike the z-test, the population variance is unknown. The sample variance is used to calculate the test statistic instead. 

Similarly to the z-test, the appropriate critical value $c$ is defined by the tails of the t-distribution (Fig 2). For a significance level $\alpha$, $H_0: \mu=\mu_0$ is rejected if $T_{stat}>t_{1-\alpha/2,n-1}$ or $T_{stat}<t_{\alpha/2,n-1}$, where $t_{1-\alpha/2,n-1}$ and $t_{\alpha/2,n-1}$ are upper and lower quantiles of order $1-\alpha$ and $\alpha/2$ for a t-distribution.  In essence, if $|T_{stat}|>t_{1-\alpha/2,n-1}$, then the $H_A: \mu\neq\mu_0$ is favored.

Again, the lower the $\alpha$ level the harder it is to reject $H_0$ as $t_{\alpha/2,n-1}$ is further on the right tail and $t_{1-\alpha,n-1}$ is further on the left tail of the t-distribution. Equivalently, the greater the magnitude of $T_{stat}$, that is, $T_{stat}>>t_{1-\alpha/2,n-1}$ or $T_{stat}<<t_{\alpha/2,n-1}$, the greater the evidence against the $H_0$ that there is no significant difference. 

The probability of getting a value $T_{stat}$ is the $p-value$. The test is significant at the $\alpha$ level if and only if $p_{value}\leq\alpha$. The probability of committing a type I error is given by:

\begin{eqnarray}
\mathbb{P}(reject \ H_0| H_0 \ true)&=&\mathbb{P}(|T_{stat}|>qt_{1-\alpha/2,n-1}|\mu=\mu_0) \\
&=&\mathbb{P}(T_{stat}>qt_{1-\alpha/2,n-1}|\mu=\mu_0) + \mathbb{P}(T_{stat}<qt_{\alpha/2,n-1}|\mu=\mu_0) \\
&=&\mathbb{P}(t>t_{1-\alpha/2,n-1}) + \mathbb{P}(t<t_{\alpha/2,n-1}|\mu=\mu_0) \\
&=&\frac{\alpha}{2} + \frac{\alpha}{2} \\
&=&\alpha.
\end{eqnarray}

Notice the Z-distribution (blue curve) and t-distribution (red curve) are slightly different from one another (Fig 2). However, as $n$ increases the t-distribution approaches the Z-distribution and the $\alpha$ levels are more and more similar. For instance, for $n=100$ and $\alpha=0.1$, $t_{0.05,100}=-1.66$ and $t_{0.95,100}=+1.66$ (Fig 2c). These critical values are very close to $z_{0.05}=-1.645$ and $z_{0.95}=+1.645$ (Fig 1a). By contrast, for $n=10$, $t_{0.05,10}=-1.812$ and $t_{0.95,10}=+1.812$ (Fig 2a). These critical values are different than $z_{0.05}$ and $z_{0.95}$.

```{r t_dist, echo=TRUE, fig.width=8, fig.height=6, fig.align='center', fig.cap='Figure 2: Z-distribution is blue curve and t-distribution is red curve with purple histograms. $H_0$ is rejected if $T_{stat}>t_{1-\\alpha/2,n-1}$ or $T_{stat}<t_{\\alpha/2,n-1}$ for the $\\alpha=0.10$ level. The $5th$ and $95th$ are the lower and upper quantiles. (a) $df=10$ and $\\alpha = 0.10$: $5th (t_{0.10/2,10}=t_{0.05,10}=-1.812)$ and $95th (t_{1-0.10/2,10}=t_{0.95,10}=+1.812)$. (b) $df=50$ and $\\alpha = 0.10$: $5th (t_{0.10/2,50}=t_{0.05,50}=-1.676)$ and $95th (t_{1-0.10/2,50}=t_{0.95,50}=+1.676)$. (c) $df=100$ and $\\alpha = 0.10$: $5th (t_{0.10/2,100}=t_{0.05,100}=-1.66)$ and $95th (t_{1-0.10/2,100}=t_{0.95,100}=-1.66)$.'}

par(mfrow=c(2,2))
hist(rt(N, df=10),
 col="violet",
 border="black",
 prob = TRUE,
 xlab = "",
 ylim = c(0.,0.4),
 xlim = c(-7.,7.),
main = TeX('$df=10$, $\\alpha$=0.10'))
curve( dnorm(x, mean=0,sd=1), add=T,col="blue", lwd = 3)
curve( dt(x, df=10), add=T,col="red", lwd = 3)
abline(v=c(-1.812,1.812), col="red", lwd = 2, lty=2)
text(-5., 0.3, TeX('t_{0.05,10}=-1.812'), col="red")
text(5., 0.3, TeX('t_{0.95,10}=+1.812'), col="red")
mtext("(a)", side=1, line = 4)

hist(rt(N, df=50),
 col="violet",
 border="black",
 prob = TRUE,
 xlab = "",
 ylim = c(0.,0.4),
 xlim = c(-7.,7.),
main = TeX('$df=50$, $\\alpha$=0.10'))
curve( dnorm(x, mean=0,sd=1), add=T,col="blue", lwd = 3)
curve( dt(x, df=10), add=T,col="red", lwd = 3)
abline(v=c(-1.676,1.676), col="red", lwd = 2, lty=2)
text(-4., 0.3, TeX('t_{0.05,50}=-1.676'), col="red")
text(4., 0.3, TeX('t_{0.95,50}=+1.676'), col="red")
mtext("(b)", side=1, line = 4)

hist(rt(N, df=100),
 col="violet",
 border="black",
 prob = TRUE,
 xlab = "",
 ylim = c(0.,0.4),
 xlim = c(-7.,7.),
main = TeX('$df=100$, $\\alpha$=0.10'))
curve( dnorm(x, mean=0,sd=1), add=T,col="blue", lwd = 3)
curve( dt(x, df=10), add=T,col="red", lwd = 3)
abline(v=c(-1.66,1.66), col="red", lwd = 2, lty=2)
text(-4., 0.3, TeX('t_{0.05,100}=-1.66'), col="red")
text(4., 0.3, TeX('t_{0.95,100}=+1.66'), col="red")
mtext("(c)", side=1, line = 4)



```


# $\mathcal{N}(100,\sigma)$ and $n=35$ 

Suppose a random sample of size $n=35$ is drawn from a normally distributed population **with $\mu_0 = 100$  and unknown variance**. The sample mean and standard deviation are given by $\bar x=104$ and $s=12$. Given that the variance is unknown, a two sided t-test (or two tailed t-test) can be used to test the null hypothesis $H_0: \mu=100$. The alternate is given by $H_A: \mu\neq 100$. Since the sample is drawn from the population, the t-test is expected to accept $H_0$.

At $\alpha=0.05$, $H_0: \mu=100$ is rejected if $T_{stat}<t_{0.025,34}$ or $T_{stat}>t_{0.975,34}$. The type I error is equal to 0.05. Notice $t_{0.025,34}=-2.228$, $t_{0.975,34}=+2.228$ and $T_{stat}=1.972$ (Fig 3a). Given that $|T_{stat}|<t_{0.975,34}$, $H_0$ is accepted and the true population parameter is $\mu_0=100$.

```{r, echo=TRUE}

mu0 <- 100
sample_mean <- 104
sample_sd <- 12
n <- 35
df <- n-1

t_stat <- sqrt(n)*(sample_mean-mu0)/sample_sd
tp_value <- 2*pt(-abs(t_stat),df) 
c(t_stat, df, tp_value)
```

The $Z_{stat}$ can't be calculated because the variance is unknown. If the z-test and t-test are used interchangeably because $n>30$, then at $\alpha=0.05$, $H_0: \mu=100$ is rejected if $T_{stat}<z_{0.025}$ or $T_{stat}>z_{0.975}$. The type I error remains equal to 0.05. $z_{0.025}$ and $z_{0.975}$ are always the same and are given by $z_{0.025}=-1.96$ and $z_{0.975}=+1.96$ (Fig 3b). Unlike the t-test, for the z-test $|T_{stat}|>z_{0.975}$. Hence, $H_0$ is **incorrectly rejected** in favor of $H_A$ and the true population parameter is $\mu_0\neq 100$. A type I error is commited when the z-test is used instead of the t-test.

```{r, echo=TRUE}

z_stat <- t_stat
zp_value <- 2*pnorm(abs(z_stat), mean = 0, sd = 1,  lower.tail = FALSE)
c(z_stat, zp_value)
```

```{r t_test_z_test, echo=TRUE, fig.width=6, fig.height=8, fig.align='center', fig.cap='Figure 3: $H_0$ is rejected if $T_{stat}>t_{1-\\alpha/2,n-1}$ or $T_{stat}<t_{\\alpha/2,n-1}$ for each $\\alpha$ level. (a) $df=34$ and $\\alpha = 0.10$: $5th (t_{0.10/2,34}=t_{0.05,34}=-1.69)$ and $95th (t_{1-0.10/2,34}=t_{0.95,34}=+1.69)$ are the lower and upper quantiles. $df=34$ and $\\alpha = 0.05$: $2.5th (t_{0.05/2,34}=t_{0.025,34}=-2.03)$ and $97.5th (t_{1-0.05/2,34}=t_{0.975,34}=+2.03)$ are the lower and upper quantiles. $df=34$ and $\\alpha = 0.01$: $0.5th (t_{0.01/2,34}=t_{0.005,34}=-2.728)$ and $99.5th (t_{1-0.01/2,34}=t_{0.995,34}=-2.728)$ are the lower and upper quantiles. (b) $\\alpha = 0.10$: $5th (z_{0.10/2}=z_{0.05}=-1.645)$ and $95th (z_{1-0.10/2}=z_{0.95}=+1.645)$ are the lower and upper quantiles. $\\alpha = 0.05$: $2.5th (z_{0.05/2}=z_{0.025}=-1.96)$ and $97.5th (z_{1-0.05/2}=z_{0.975}=+1.96)$ are the lower and upper quantiles. $\\alpha = 0.01$: $0.5th (z_{0.01/2}=z_{0.005}=-2.575)$ and $99.5th (z_{1-0.01/2}=z_{0.995}=-2.575)$ are the lower and upper quantiles.'}


par(mfrow=c(2,1))
hist(rt(N, df=34),
 col="violet",
 border="black",
 prob = TRUE,
 xlab = "",
 ylim = c(0.,0.4),
 xlim = c(-7.,7.),
main = TeX('$df=34$, $\\alpha$=0.01;0.05;0.10'))
curve( dt(x, df=10), add=T,col="red", lwd = 3)
abline(v=c(-1.69,1.69), col="red", lwd = 2, lty=2)
text(-3.2, 0.3, TeX('t_{0.05,34}=-1.69'), col="red")
text(3.2, 0.3, TeX('t_{0.95,34}=+1.69'), col="red")
abline(v=c(-2.03,2.03), col="darkgreen", lwd = 2, lty=2)
text(-3.8, 0.2, TeX('t_{0.025,34}=-2.03'), col="darkgreen")
text(3.8, 0.2, TeX('t_{0.975,34}=+2.03'), col="darkgreen")
abline(v=c(-2.728,2.728), col="black", lwd = 2, lty=2)
text(-5., 0.1, TeX('t_{0.005,34}=-2.728'))
text(5., 0.1, TeX('t_{0.995,34}=+2.728'))
abline(v=t_stat, col="black", lwd = 2, lty=1)
text(5.3, 0.4, TeX('T_{stat}=+1.972'))
mtext("(a)", side=1, line = 4)

hist(population_z,
 col="yellow",
 border="black",
 prob = TRUE,
 xlab = "",
 ylim = c(0.,0.4),
main = TeX('$\\alpha$=0.01;0.05;0.10'))
curve( dnorm(x, mean=0,sd=1), add=T,col="blue", lwd = 3)
abline(v=c(-1.645,1.645), col="red", lwd = 2, lty=2)
text(-3., 0.3, TeX('z_{0.05}=-1.645'), col="red")
text(3., 0.3, TeX('z_{0.95}=+1.645'), col="red")
abline(v=c(-1.96,1.96), col="darkgreen", lwd = 2, lty=2)
text(-3.4, 0.2, TeX('z_{0.025}=-1.96'), col="darkgreen")
text(3.4, 0.2, TeX('z_{0.975}=+1.96'), col="darkgreen")
abline(v=c(-2.575,2.575), col="black", lwd = 2, lty=2)
text(-4., 0.1, TeX('z_{0.005}=-2.575'))
text(4., 0.1, TeX('z_{0.995}=+2.575'))
abline(v=z_stat, col="black", lwd = 2, lty=1)
text(4.3, 0.4, TeX('T_{stat}=+1.972'))
mtext("(b)", side=1, line = 4)
```

